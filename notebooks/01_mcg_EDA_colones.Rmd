---
title: "R Notebook"
output:
  html_document:
    df_print: paged
  html_notebook: default
  word_document: default
---

```{r}
library(here)
library(readxl)
#library(papeR)
library(outliers)
library(kableExtra)
library(DataExplorer)
library(lubridate)
library(forecast)
library(nortest)
library(tidyverse)
library(ggfortify)

```

Rutas
```{r}
raw_data <- here("data", "raw")
interim_data <- here("data", "interim")
final_data <- here("data", "processed")

```

Leyendo base de datos
```{r}
base <- read_excel(paste0(raw_data,"/Base Datos.xlsx"), 
    col_types = c("text", "numeric", "numeric"))

head(base)
```

Extrayendo la base de colones y de dolares
```{r}

colones <- data_frame(date = base$`Activo neto`,
                  col =  as.double(base$CRC)) %>%
  mutate(date = ymd(paste0(date, "-01"))) %>%
  mutate(year = as.factor(year(date)),
         month = as.factor(month(date)))

head(colones)
```

Convirtiendo los datos a series de tiempo
```{r}
# Colones

# 6 periodos para utilizar a modo de validación
colones_val <- colones %>% 
  slice_tail(n = 6)

# Serie completa para el analisis exploratorio
colones_full <- colones

# 10 años de datos para modelar
colones <- colones %>% 
  filter(date>"2007-12-01")

# Objetos ts tanto para la serie completa como para la serie de modelado
colones_ts_full <- ts(colones_full$col, start = c(2001,2), frequency = 12)
colones_ts <- ts(colones$col, start = c(2008,1), frequency = 12)

```


# 1 - Analisis exploratorio

## 1.1 - Exploracion de datos 
## Colones

```{r  warning=FALSE}
plot_histogram(colones$col)

```

```{r}

colones %>% 
  summarise(across(col, list(media = mean, minimo = min, maximo = max, desv = sd),.names = "{.fn}")) %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

colones %>% 
  group_by(year) %>% 
  summarise(across(col, list(media = mean, minimo = min, maximo = max, desv = sd),.names = "{.fn}")) %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

colones %>% 
  group_by(month) %>% 
  summarise(across(col, list(media = mean, minimo = min, maximo = max, desv = sd),.names = "{.fn}")) %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```
La media del total de fondos es de 386557.8 y varía entre 11067.66 y 1023249 con una
desviación estandar de  272344.6.

Se puede apreciar que el promedio anual de fondos se mantiene creciendo desde el primer año
y se duplica cada aproximadamente 5 años y es claro que en el 2020 hay un aumento 
considerable en el promedio pues para de esta alrededor de 650 mil a pasar a casi
900mil. 

Por otro lado, cuando vemos los estadísticos por cada mes, se observa que claramente la temporada de fin de año (noviembre y diciembre) tiene un promedio mas bajo que el resto en contraste con
los meses de enero y julio en donde hay mayores promedios. Esto puede evidenciar
salidas de dinero en los meses de mas consumo como son las vacaciones de diciembre
y las de mediados de año que vienen seguidas por un aumento pues se vuelve a colocar
el dinero en los fondos. 


## 1.2 - Analisis de valores extremos

```{r echo=FALSE}
outliers::outlier(colones_ts, opposite = FALSE, logical = FALSE)
#no se rechaza
grubbs.test(colones_ts, type = 10, opposite = FALSE, two.sided = TRUE) # one outlier
#se rechaza
chisq.out.test(colones_ts, opposite = FALSE)

```

Después de hacer el análisis de valores extremos, una de las 2 pruebas se rechaza (chi cuadrado) que determina que el valor 1023248.6231 (Julio del 2020) es un valor extremo. Aunque si lo vemos en el contexto y particularmente comparado con los otros meses de Julio se aprecia que en general tienen valores altos. Por esto y sumado a que es una serie que viene en constante crecimiento a largo del 
año se mantiene el valor para el resto del análisis. 

## 1.3 - Primeros graficos
```{r warning=FALSE}
#GRAFICO ACCIDENTES
plot.ts(colones_ts_full,ylab='Montos (COL)',xlab="Periodo",main="Activo neto en colones por mes\n(2001 - 2020)", lty=5,col="darkgray",bty="l",lwd=3)
Month=c('J','F','M','A','M','J','J','A','S','O','N','D')
points(colones_ts_full,pch=Month,col="blue")


autoplot(colones_ts_full)+
 # geom_point(Month)+
  scale_x_date(date_labels="%Y",date_breaks  ="2 year")+
  labs(title = "Activo neto en colones por mes\n(2001 - 2020)",
             # subtitle = "Plot of length by dose",
              caption = "Fuente: SUGEVAL (2020)",
       x= "Periodo",
       y= "Montos (COL)")+
  theme(
    plot.title = element_text(hjust = 0.5)
    )



```

### 1.3.1 - Analisis por mes
```{r  warning=FALSE}

seasonplot(colones_ts_full,col=viridis::viridis(12),year.labels=TRUE, main = "Activo neto en colones por mes\n(2001 - 2020)")

monthplot(colones_ts_full,col="blue", main= "Activo neto en colones por mes\n(2001 - 2020)")

```

En el gráfico se puede observar que hay tendencia de aumento a través de los casi 19 años
analizados, y se aprecia que hubo un aumento considerable entre los años 2008 y 2010
lo que se podría interpretar como una respuesta a la crisis del 2008 y luego hubo otro aumento 
cerca del 2014-2015 y por último el aumento 
a partir de abril del 2020 lo cual es evidente que es a causa del COVID-19. 
En términos de estacionalidad se observa que efectivamente el promedio durante Noviembre y
Diciembre decrece y sube en Enero y Julio. También se observa que si bien no hay muchas
diferencias de mes a mes si hay mucha variabilidad y no hay excepciones en el crecimiento
continuo.
Además, debido a que la variabilidad de la serie parece mantenerse a través del tiempo es posible sospechar que la serie es aditiva, por lo tanto, la descomposición se hará partiendo de esto. 


## 1.4 - Descomposición de la serie (aditiva)

```{r  warning=FALSE}
decompose_colones_full = decompose(colones_ts_full, "additive")

plot(as.ts(decompose_colones_full$seasonal), xlab="", ylab="Componente estacional", main= "Activo neto en colones \n(2001 - 2020)")
plot(as.ts(decompose_colones_full$trend), xlab="", ylab="Componente tendencia",  main= "Activo neto en colones \n(2001 - 2020)")
plot(as.ts(decompose_colones_full$random), xlab="", ylab="Componente aleatorio",  main= "Activo neto en colones \n(2001 - 2020)")
plot(decompose_colones_full, xlab="")

```

Se aprecia en el primer gráfico que la serie es altamente estacional pues se presenta un patrón regular en forma reiterada. Por otro lado, se observa que la tendencia, aunque mayormente creciente, posee cierta ciclicidad pues posee un pico pronunciado alrededor del año 2008, del 2014 y del 2020. Finalmente, el componente aleatorio es altamente variable pero se observa que la variabilidad va en aumento 
conforme pasa el tiempo y sobretodo a partir del 2014 por lo tanto se procede a descomponer 
la serie pero esta vez multiplicativa. 

## 1.4 - Descomposición de la serie (multiplicativa)

```{r  warning=FALSE}
decompose_colones_full = decompose(colones_ts_full, "multiplicative")

plot(as.ts(decompose_colones_full$seasonal), xlab="", ylab="Componente estacional", main= "Activo neto en colones \n(2001 - 2020)")
plot(as.ts(decompose_colones_full$trend), xlab="", ylab="Componente tendencia",  main= "Activo neto en colones \n(2001 - 2020)")
plot(as.ts(decompose_colones_full$random), xlab="", ylab="Componente aleatorio",  main= "Activo neto en colones \n(2001 - 2020)")
plot(decompose_colones_full, xlab="")

```
Con respecto a la parte estacional y de tendencia se puede concluir lo mismo que en el 
caso aditivo pero el componente aleatorio esta vez si tiene a verse mas cercano al
ruido blanco o sin ninguna tendencia clara. La serie, por ende, se va a analizar de forma
multiplicativa. 


## 1.5 - Histograma y test de normalidad para los errores

### 1.5.1 - Histogramas y gráficos para determinar normalidad (Accidentes)

```{r  warning=FALSE}
# Accidentes aditivo
errores <- decompose_colones_full$random 

hist(errores,breaks="Sturges",freq=T, include.lowest = TRUE, col="blue",border="darkred", ylab = "Frecuencia", main = "Histograma de los errores de la\nActivo neto de los fondos del mercado de dinero (Sturges)")

hist(errores,breaks="Scott",freq=T, include.lowest = TRUE, col="blue",border="darkred", ylab = "Frecuencia", main = "Histograma de los errores de la\nActivo neto de los fondos del mercado de dinero (Scott)")

hist(errores,breaks="FD",freq=T, include.lowest = TRUE, col="blue",border="darkred", ylab = "Frecuencia", main = "Histograma de los errores de la\nActivo neto de los fondos del mercado de dinero (FD)")

hist(errores,freq=T, include.lowest = TRUE, col="blue",border="darkred",nclass=10, ylab = "Frecuencia", main = "Histograma de los errores de la\nActivo neto de los fondos del mercado de dinero")

qqnorm(errores, main = "QQplot de los errores de la\nActivo neto de los fondos del mercado de dinero")

boxplot(errores, main = "Boxplot de los errores de la\nActivo neto de los fondos del mercado de dinero")
```

A partir de todos los histogramas (con cortes de forma automático, de Sturges, de Scott y FD) se puede apreciar que la distribución de los errores es aproximadamente normal con media cero. Además, el boxplot y el qqplot aportan mas evidencias visuales de que los residuales se distribuyen de forma normal con media cero. Pero esto debe corroborarse con pruebas de hipótesis formales.

### 1.5.2 - Prueba formal de normalidad donde la Ho: La muestra proviene de una distribución normal 
(Activo neto de los fondos del mercado de dinero)

```{r  warning=FALSE}
#Prueba de Anderson-Darling
ad.test(errores) 

#Prueba de Cramer-von Mises
cvm.test(errores) 

#Prueba de Lilliefors (Kolmogorov-Smirnov)
lillie.test(errores) 

#Prueba de Pearson chi-square
pearson.test(errores) 

#Prueba de Shapiro-Francia
sf.test(errores) 

#Prueba de Agostino
moments::agostino.test(errores) 

#Prueba de Shapiro-Wilk
shapiro.test(errores) 
```

Se realizaron 7 pruebas distintas para comprobar, de manera formal, que los errores de la serie analizada de distribuyen normalmente. Estos estadísticos fueron: prueba de Anderson-Darling, prueba de Cramer-von Mises, prueba de Lilliefors, prueba de Pearson, prueba de Shapiro-Francia, prueba de D'agostino y prueba de Shapiro-Wilk. Para todas estas, la hipótesis nula es que la muestra se distribuye normalmente, y al analizarla con un nivel de significancia del 95% se concluye para 3 de ellas que no se rechaza la hipótesis nula mientras que 4 de ellas si la rechazan. No hay un criterio claro en términos de pruebas de 
hipótesis a pesar de que visualmente se observa que los errores parecen normales. 
Estas pruebas pueden estarse rechazando por algunos valores extremos, como los vistos antes, 
entonces podríamos asumir que los errores son normales.

### 1.5.3 - Prueba formal de autocorrelación de los errores donde la Ho: no hay autocorrelación

```{r  warning=FALSE}
errores_m <- as.matrix(errores)
#x7
errores_m<- errores_m[7:228,]
#x77
Box.test(errores_m, type = "Ljung-Box")

```

Para comprobar la auto-correlación de los errores se utilizó la prueba de Box-Ljung y con un nivel de significancia del 95% no se rechaza la hipótesis nula de que no hay correlación en la muestra, es por esto que podemos concluir que no hay correlación en los errores de la serie de homicidios lo cual, junto con la comprobación de la normalidad anterior, permite proseguir con el análisis pues la serie no presenta mayores problemas en cuanto a los supuestos de los modelos lineales.


